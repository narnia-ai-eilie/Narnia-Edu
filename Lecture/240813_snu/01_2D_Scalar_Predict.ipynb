{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "FQzXEbGCoerK",
        "SpSS_orNomwE",
        "g3ybYdw7--HX"
      ],
      "authorship_tag": "ABX9TyNLd8D/zLMzXvZbwHgiWcos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EilieYoun/Narnia-Edu/blob/main/Lecture/240813_snu/01_2D_Scalar_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 서울대 예측 AI 실습 : 2D Scalar Predict\n",
        "\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "\n",
        "## 학습내용\n",
        "```\n",
        "- 2D 데이터셋에 대해 이해하고 적절한 DataLoader를 구성 한다.\n",
        "- 2D scalar 예측 문제에 적합한 모델을 구성하고, 학습을 진행한다.\n",
        "```"
      ],
      "metadata": {
        "id": "1PpOHlxlnDvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(0) 환경세팅**\n",
        "---"
      ],
      "metadata": {
        "id": "XxQZXje__Db7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 라이브러리 설치**"
      ],
      "metadata": {
        "id": "FQzXEbGCoerK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "id": "lxaWDEQHdd5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "02Ewuw33ad6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 데이터 압축 풀기**"
      ],
      "metadata": {
        "id": "SpSS_orNomwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder  https://drive.google.com/drive/u/0/folders/1E5OP-VCqgh8wEaQO-jXdvRH3dQZtI_Vp"
      ],
      "metadata": {
        "id": "M90wrwHETSTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/데이터/carhood_npy.zip -d carhood_npy"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xJr20EeuwDjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Utils**"
      ],
      "metadata": {
        "id": "g3ybYdw7--HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "from PIL import Image\n",
        "\n",
        "def draw_scatter_plotly(df, name, x, y, sample=None, marker_size=8, plot_width=700, plot_height=500):\n",
        "    if sample is not None:\n",
        "        df = df.sample(sample)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Scatter plots\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df[x],\n",
        "        y=df[y],\n",
        "        mode='markers',\n",
        "        marker=dict(size=marker_size, color='blue'),\n",
        "        text=df[name],  # Hover할 때 보일 텍스트 설정\n",
        "        hoverinfo='text+x+y',  # Hover할 때 name, x, y 값만 보이도록 설정\n",
        "        name=f'{x} vs {y}'\n",
        "    ))\n",
        "\n",
        "    # 레이아웃 설정\n",
        "    fig.update_layout(\n",
        "        title=f'{x} vs {y}',\n",
        "        xaxis_title=x,\n",
        "        yaxis_title=y,\n",
        "        width=plot_width,\n",
        "        height=plot_height\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "def draw_img_from_cond(skin, geo, cmap='gray'):\n",
        "    plt.figure(figsize=(3,3))\n",
        "    path = f'carhood_npy/skin_{skin}_geometry_{geo}.npy'\n",
        "    img = np.load(path)\n",
        "    plt.imshow(img, cmap=cmap)\n",
        "    plt.show()\n",
        "    return img\n",
        "\n",
        "\n",
        "def draw_3d(depth_map):\n",
        "    # 3D 플로팅\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # x, y 좌표 생성\n",
        "    x = np.arange(0, depth_map.shape[1], 1)\n",
        "    y = np.arange(0, depth_map.shape[0], 1)\n",
        "    x, y = np.meshgrid(x, y)\n",
        "\n",
        "\n",
        "    ax2 = fig.add_subplot(131, projection='3d')\n",
        "    surface2 = ax2.plot_surface(x, y, depth_map, cmap='viridis')\n",
        "    ax2.set_axis_off()\n",
        "    ax2.set_xlabel('X')\n",
        "    ax2.set_ylabel('Y')\n",
        "    ax2.set_zlabel('Depth')\n",
        "    ax2.view_init(elev=0, azim=90)\n",
        "\n",
        "    ax = fig.add_subplot(132, projection='3d')\n",
        "    surface1 = ax.plot_surface(x, y, depth_map, cmap='viridis')\n",
        "    ax.set_axis_off()\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Depth')\n",
        "    ax.view_init(elev=60, azim=60)\n",
        "\n",
        "\n",
        "    ax1 = fig.add_subplot(133, projection='3d')\n",
        "    surface1 = ax1.plot_surface(x, y, depth_map, cmap='viridis')\n",
        "    ax1.set_axis_off()\n",
        "    ax1.set_xlabel('X')\n",
        "    ax1.set_ylabel('Y')\n",
        "    ax1.set_zlabel('Depth')\n",
        "    fig.colorbar(surface1, ax=ax1, shrink=0.5, aspect=10)\n",
        "    ax1.view_init(elev=0, azim=30)\n",
        "\n",
        "    # 플롯 출력\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def draw_dist(inputs, samples=100):\n",
        "    if len(inputs) > samples:\n",
        "        inputs = random.sample(list(inputs), samples)\n",
        "\n",
        "    pixel_values = []\n",
        "    for item in inputs:\n",
        "        if isinstance(item, Image.Image):\n",
        "            pixel_values.extend(list(item.getdata()))\n",
        "        elif isinstance(item, np.ndarray):\n",
        "            pixel_values.extend(item.flatten())\n",
        "        elif torch.is_tensor(item):\n",
        "            if len(item.shape) == 4 and item.shape[1] == 1:  # 이미지가 (batch_size, 1, height, width) 꼴일 때\n",
        "                item = item.squeeze(1)\n",
        "            elif len(item.shape) == 3:  # 이미지가 (batch_size, height, width) 꼴일 때\n",
        "                item = item.unsqueeze(1)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image shape. Supported shapes: (batch_size, height, width) or (batch_size, 1, height, width).\")\n",
        "            item = item.detach().cpu().numpy()\n",
        "            pixel_values.extend(item.flatten())\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported image type. Supported types: PIL Image, numpy array, torch tensor.\")\n",
        "\n",
        "    plt.figure(figsize=(5,3))\n",
        "    plt.hist(pixel_values, bins=20, color='blue', alpha=0.7)\n",
        "    plt.xlabel('Pixel Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Image Pixel Value Distribution')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def draw_imgs(images_list,\n",
        "             r=1,\n",
        "             cmap='gray',\n",
        "             img_size=(5, 5),\n",
        "             axis=\"off\",\n",
        "             colorbar=False,\n",
        "             save_path=None,):\n",
        "    if r < 1:\n",
        "        r = 1\n",
        "\n",
        "    total_images = len(images_list)\n",
        "    if total_images == 0:\n",
        "        print(\"No images to display.\")\n",
        "        return\n",
        "\n",
        "    cols = (total_images + r - 1) // r\n",
        "    fig, axs = plt.subplots(r, cols, figsize=(cols * img_size[0], r * img_size[1]))\n",
        "\n",
        "    if r == 1:\n",
        "        axs = axs.reshape(1, -1)\n",
        "\n",
        "    for idx, item in enumerate(images_list):\n",
        "        ax = axs[0, idx] if r == 1 else axs[idx // cols, idx % cols]\n",
        "        im = None\n",
        "        if isinstance(item, Image.Image):\n",
        "            if item.mode in ['L', '1']:  # Grayscale images\n",
        "                im = ax.imshow(item, cmap=cmap)\n",
        "            else:  # Color images\n",
        "                im = ax.imshow(item)\n",
        "        elif isinstance(item, np.ndarray):\n",
        "            if item.ndim == 2:  # 2D array, grayscale image\n",
        "                im = ax.imshow(item, cmap=cmap)\n",
        "            elif item.ndim == 3:  # 3D array, color image\n",
        "                im = ax.imshow(item, cmap=cmap if item.shape[-1] == 1 else None)\n",
        "            elif item.ndim == 4 and item.shape[0] == 1:  # 4D array with batch dimension of 1\n",
        "                im = ax.imshow(item[0], cmap=cmap if item.shape[1] == 1 else None)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported numpy array shape: {item.shape}.\")\n",
        "        elif torch.is_tensor(item):\n",
        "            item = item.detach().cpu().numpy()\n",
        "            if item.ndim == 2:  # 2D tensor, grayscale image\n",
        "                im = ax.imshow(item, cmap=cmap)\n",
        "            elif item.ndim == 3:  # 3D tensor, color image\n",
        "                im = ax.imshow(item.transpose(1, 2, 0), cmap=cmap if item.shape[0] == 1 else None)\n",
        "            elif item.ndim == 4 and item.shape[0] == 1:  # 4D tensor with batch dimension of 1\n",
        "                im = ax.imshow(item[0].transpose(1, 2, 0), cmap=cmap if item.shape[1] == 1 else None)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported torch tensor shape: {item.shape}.\")\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported image type. Supported types: PIL Image, numpy array, torch tensor.\")\n",
        "\n",
        "        if colorbar and im is not None:\n",
        "            divider = make_axes_locatable(ax)\n",
        "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "            fig.colorbar(im, cax=cax)\n",
        "\n",
        "        ax.axis(axis)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    # 이미지 저장\n",
        "    if save_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        plt.savefig(save_path, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def draw_results(preds, targets, titles=[]):\n",
        "\n",
        "    num_vars = preds.shape[1]\n",
        "\n",
        "    # 그래프 크기 설정\n",
        "    fig, axes = plt.subplots(1, num_vars, figsize=(num_vars * 6, 6))\n",
        "\n",
        "    for i in range(num_vars):\n",
        "        ax = axes[i]\n",
        "        ax.scatter(targets[:, i], preds[:, i], alpha=0.5)\n",
        "        ax.plot([targets[:, i].min(), targets[:, i].max()], [targets[:, i].min(), targets[:, i].max()], 'r--')\n",
        "        ax.set_xlabel('Actual')\n",
        "        ax.set_ylabel('Predicted')\n",
        "\n",
        "        if titles and i < len(titles):\n",
        "            ax.set_title(titles[i])\n",
        "        else:\n",
        "            ax.set_title(f'Variable {i+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WLUUO_O5-9hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(1) Dataset**"
      ],
      "metadata": {
        "id": "vvsJn35E_F_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| EDA**\n",
        "\n",
        "**데이터 소개**\n",
        "\n",
        "\n",
        "`CarHoods10k` 데이터셋은 10,000개 이상의 자동차 후드 프레임 3D 메쉬 형상으로 구성되었으며, 자동화된 CAD 워크플로우를 통해 생성되었습니다. 이 데이터셋은 현실성과 제조 가능성에 대해 전문가의 검증을 거쳤습니다. 기초 형상 및 FEA(유한 요소 해석) 성능 지표가 포함되어 있으며, 자동차 공학 및 기타 분야에서 최적화 및 머신러닝 방법을 평가하고 개발하는 데 유용한 데이터를 제공합니다​ (DataDryad)​.\n",
        "\n",
        "`CarHoods10k` 데이터셋은 `Creative Commons Zero (CC0)` 라이센스로 제공됩니다. 이 라이센스는 사용자가 저작권을 포기한 것으로, 누구나 자유롭게 데이터를 복제, 수정, 배포, 심지어 상업적 목적으로도 사용할 수 있습니다. 사용자는 출처를 명시할 필요가 없으며, 데이터 사용에 대한 법적 제한이 없습니다\n",
        "\n",
        "이번 시간에 다룰 데이터는 `CarHood10k` 메쉬 데이터셋을 256x256 해상도의 depthmap으로 가공한 것입니다. 전체 데이터 중 무작위로 선택한 1,000개의 `depthmap npy` 파일을 사용하여 실습을 진행할 예정입니다. 이 데이터를 통해 자동차 후드의 성능을 예측하는 방법을 배우고자 합니다."
      ],
      "metadata": {
        "id": "J4BD_y6coTZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**성능 변수 확인**\n",
        "\n",
        "\n",
        "\n",
        "* `Equivalent Stress Maximum (MPa)`: 이 값은 von Mises stress의 최대값을 의미합니다. von Mises stress는 재료의 복잡한 응력 상태를 단일 응력 값으로 나타내는 방법 중 하나입니다.  von Mises stress 값이 낮을 수록 동일한 하중 조건에서 제품의 파손이 잘 발생하지 않기 때문에 Car hood의 안전성을 판단하는데 사용됩니다.\n",
        "\n",
        "\n",
        "* `Geometry Mass (kg)`: 이 값은 Car hood의 질량을 나타내며, 일반적으로 제품의 무게를 측정하는 데 사용됩니다. 일반적으로는 Car hood가 더 가벼을수록 연료 효율성이 좋아지고, 주행 성능이 향상될 수 있습니다.\n",
        "\n",
        "* `Directional Deformation Maximum (mm)`: 이 값은 Car hood의 변형량 중에서 가장 큰 값입니다. 이 값이 작을수록 Car hood가 보다 견고하고, 형태 유지가 뛰어남을 의미합니다. 따라서 작은 값이 더 좋습니다."
      ],
      "metadata": {
        "id": "cDSch-dN3bG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/데이터/carhood_annot.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kGOnsBXofPSb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 분포 시각화**"
      ],
      "metadata": {
        "id": "PwdX6SblxrLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(df.columns)\n",
        "print(cols)\n",
        "\n",
        "draw_scatter_plotly(df, cols[0], cols[2], cols[1])\n",
        "draw_scatter_plotly(df, cols[0], cols[2], cols[3])\n",
        "draw_scatter_plotly(df, cols[0], cols[1], cols[3])"
      ],
      "metadata": {
        "id": "X38Yp-7h7WRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Depthmap 이미지 시각화**"
      ],
      "metadata": {
        "id": "U821VvShxtzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = draw_img_from_cond(41, 29)\n",
        "print(img.shape)\n",
        "draw_3d(img)\n",
        "draw_dist([img])"
      ],
      "metadata": {
        "id": "xSFMO5rFu-0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| DataLoader**\n",
        "\n",
        "간략하게 데이터 구성을 확인했으니 이를 적절한 DataLoader 클래스를 구축하겠습니다. DataLoader는 아래와 같은 기능이 포함되어야 합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 데이터셋 초기화.\n",
        "    - df: 데이터프레임, 메타데이터를 포함.\n",
        "    - data_dir: 데이터 파일 경로.\n",
        "    - name_column: 데이터 파일 이름을 포함하는 열.\n",
        "    - var_columns: 정규화할 변수 열.\n",
        "    - scaler: 데이터 정규화에 사용할 스케일러, 없으면 StandardScaler를 사용.\n",
        "    - batch_size: 배치 크기.\n",
        "    - shuffle: 데이터 셔플 여부.\n",
        "    - dtype: 데이터 유형 (torch.float32 기본값).\n",
        "\n",
        "- __len__ : 데이터셋의 전체 길이를 반환.\n",
        "\n",
        "- __getitem__ : 인덱스에 해당하는 데이터 항목을 반환.\n",
        "    - DataFrame을 로드하여 필요한 데이터 불러오기\n",
        "    - Numpy 데이터를 적절하게 정규화\n",
        "    - 성능 변수를 적절하게 정규화\n",
        "    - 전처리된 인풋 텐서 (x)와 타깃 텐서 (y) 반환\n",
        "\n",
        "- get_loader : 데이터 로더를 반환.\n",
        "\n",
        "- get_batch : 지정된 인덱스의 배치를 반환.\n",
        "```\n"
      ],
      "metadata": {
        "id": "XVI4QnmYA7t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class CarHoodProcess(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 df,\n",
        "                 data_dir,\n",
        "                 name_column,\n",
        "                 var_columns=[],\n",
        "                 scaler=None,\n",
        "                 batch_size=32,\n",
        "                 shuffle=True,\n",
        "                 dtype=torch.float32\n",
        "                ):\n",
        "        # init\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.name_column = name_column\n",
        "        self.var_columns = var_columns\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.dtype = dtype\n",
        "\n",
        "        if scaler is None:\n",
        "            self.scaler = StandardScaler()\n",
        "            self.scaler.fit(self.df[self.var_columns])\n",
        "        else:\n",
        "            self.scaler = scaler\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        items = self.df.iloc[idx]\n",
        "\n",
        "        name = items[self.name_column]\n",
        "        path = f'{data_dir}/{name}.npy'\n",
        "        arr = np.load(path)\n",
        "\n",
        "        non_zero_values = arr[np.where(arr != 0)]\n",
        "        mean = np.mean(non_zero_values)\n",
        "        std = np.std(non_zero_values)\n",
        "        normalized_values = (non_zero_values - mean) / std\n",
        "\n",
        "        x = np.zeros_like(arr)\n",
        "        x[np.where(arr != 0)] = normalized_values\n",
        "        x = torch.tensor(x, dtype=self.dtype)\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        y = list(items[self.var_columns])\n",
        "        df = pd.DataFrame([y], columns=self.var_columns)\n",
        "        y = self.scaler.transform(df)  # 정규화\n",
        "        y = torch.tensor(y[0], dtype=self.dtype)\n",
        "        return x, y\n",
        "\n",
        "    def get_loader(self):\n",
        "        loader = DataLoader(self, batch_size=self.batch_size, shuffle=self.shuffle, pin_memory=True)\n",
        "        return loader\n",
        "\n",
        "    def get_batch(self, idx=0):\n",
        "        ds = self.get_loader()\n",
        "        for i, batch in enumerate(ds):\n",
        "            if i == idx : break\n",
        "        return batch"
      ],
      "metadata": {
        "id": "VIKvfPO5E1jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader 테스트**"
      ],
      "metadata": {
        "id": "8hXfUOTQyuSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'carhood_npy'\n",
        "name_column =  'name'\n",
        "var_columns = [cols[1], cols[2], cols[3]]\n",
        "batch_size = 32\n",
        "\n",
        "pp = CarHoodProcess(df, data_dir, name_column, var_columns, batch_size=batch_size, shuffle=True)\n",
        "xs, ys = pp.get_batch(0)\n",
        "print(xs.shape, ys.shape)\n",
        "#print(ys[:8])\n",
        "\n",
        "draw_imgs(xs[:8, 0])\n",
        "draw_dist(xs)"
      ],
      "metadata": {
        "id": "2LNW1vF-ydjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 분할**"
      ],
      "metadata": {
        "id": "f2kyjoXFyxdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.sample(frac=0.95, random_state=42)\n",
        "test_df = df.drop(train_df.index)\n",
        "print(train_df.shape, test_df.shape)"
      ],
      "metadata": {
        "id": "86CES0TbZIVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processor 구축**"
      ],
      "metadata": {
        "id": "Lahxh2CCy09u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='./carhood_npy'\n",
        "name_column='name'\n",
        "var_columns=[cols[1], cols[2], cols[3]]\n",
        "batch_size=32\n",
        "\n",
        "train_pp = CarHoodProcess(train_df, data_dir, name_column, var_columns, batch_size=batch_size, shuffle=True)\n",
        "test_pp = CarHoodProcess(test_df, data_dir, name_column, var_columns, batch_size=batch_size, shuffle=False, scaler=train_pp.scaler)"
      ],
      "metadata": {
        "id": "LR-47qmJK562"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV1cR283HndF"
      },
      "source": [
        "\n",
        "## **(2) 모델**\n",
        "---\n",
        "\n",
        "이번 시간에 사용할 모델은 `EfficientNet`입니다. `EfficientNet`은 신경망의 크기를 균형 있게 확장하여 높은 성능과 효율성을 달성하는 이미지 분류 모델입니다. 이 모델은 이미지넷 데이터셋에서 뛰어난 성능을 보였으며, 다양한 크기의 모델 변형이 제공됩니다.\n",
        "\n",
        "`EfficientNet`은 `efficientnet_pytorch` 라이브러리에서 쉽게 불러올 수 있습니다. 이 라이브러리는 `PyTorch`에서 `EfficientNet` 모델을 간편하게 사용할 수 있도록 지원하며, 모델 가중치도 포함되어 있어 손쉽게 학습된 모델을 사용할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Structure 구축**\n",
        "\n",
        "* 이미지 출처 : (https://www.researchgate.net/figure/The-EffecientNet-B0-general-architecture_fig2_348470984)\n",
        "\n",
        "\n",
        "![](https://www.researchgate.net/publication/348470984/figure/fig2/AS:979961129209859@1610652348348/The-EffecientNet-B0-general-architecture.png)\n",
        "\n",
        "이 부분에서는 `EfficientNet` 기반 회귀 모델인 `EfficientNetRegressor`의 구조를 정의합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 사전 학습된 `EfficientNet` 모델을 불러오고 문제에 맞게 적절히 변환합니다.\n",
        "    - model_name : 불러 올 EfficientNet 의 버전을 선택합니다.\n",
        "    - in_channels : 첫번째 컨볼루션 레이어의 입력 channel 개수 입니다.\n",
        "    - out_features : 마지막 완전연결 레이어의 출력 feature 개수 입니다.\n",
        "\n",
        "- forward : 입력 데이터를 모델에 전달하여 예측 값을 반환합니다.\n",
        "```\n"
      ],
      "metadata": {
        "id": "Sv3wyN7O0hZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class EfficientNetRegressor(nn.Module):\n",
        "    def __init__(self, model_name, in_channels=1, out_features=3):\n",
        "        super(EfficientNetRegressor, self).__init__()\n",
        "        self.base_model = EfficientNet.from_pretrained(model_name)\n",
        "        self.base_model._conv_stem = nn.Conv2d(in_channels, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        self.base_model._fc = nn.Linear(self.base_model._fc.in_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)"
      ],
      "metadata": {
        "id": "zcMPRi_DdJDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EfficientNet 모델 생성**\n"
      ],
      "metadata": {
        "id": "KJaY8tl8z_y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnet ="
      ],
      "metadata": {
        "id": "B_Dga5mYdvyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 입력과 출력 확인**"
      ],
      "metadata": {
        "id": "vE79wsrk0CJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 1, 256, 256)  # (batch_size, channels, height, width)\n",
        "\n",
        "print(inputs.shape, outputs.shape)  # 예측 출력 shape 확인"
      ],
      "metadata": {
        "id": "MIyPaQ6PnPUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 모델 구축**\n",
        "\n",
        "`PyTorch Lightning`을 사용하여 훈련, 검증, 최적화 루틴을 포함하는 `CarhoodPredictor`를 정의합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 예측 모델(predictor)을 초기화합니다.\n",
        "- forward : 입력 데이터를 예측 모델에 전달하여 출력을 반환합니다.\n",
        "- configure_optimizers : Adam 옵티마이저와 코사인 조정 학습률 스케줄러를 설정합니다.\n",
        "- training_step : 훈련 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 손실을 계산하여 로깅합니다.\n",
        "- validation_step : 검증 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 손실을 계산하여 로깅합니다.\n",
        "- fit : 훈련 및 검증 데이터를 사용하여 모델을 훈련합니다. 조기 종료와 체크포인트 저장 기능을 포함합니다.\n",
        "- test_step : 테스트 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, R² 점수와 MAE를 포함한 성능 지표를 로깅합니다.\n",
        "- test : 테스트 데이터를 사용하여 모델 성능을 평가합니다.\n",
        "- infer : 주어진 데이터 로더에서 예측을 수행하고, 필요 시 스케일러를 사용하여 예측값을 역변환합니다.\n",
        "```"
      ],
      "metadata": {
        "id": "kciU309YeJg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import  CSVLogger\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "class CarhoodPredictor(pl.LightningModule):\n",
        "    def __init__(self, structure, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.structure = structure\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.structure(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.init_lr)\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
        "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"epoch\"}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('learning_rate', lr, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss =  nn.MSELoss()(output, target)\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "\n",
        "        self.log('valid_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def fit(self, train_loader, save_dir,  valid_loader=None, init_lr=1e-3, epochs=10, patience=5):\n",
        "        self.init_lr = init_lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "        # valid loss 기준으로 최적 모델 저장하기\n",
        "        if valid_loader is not None:\n",
        "            monitor = 'valid_loss'\n",
        "        else:\n",
        "            monitor = 'train_loss'\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            dirpath=save_dir,\n",
        "            filename='ckp_model',\n",
        "            save_top_k=1,\n",
        "            verbose=True,\n",
        "            monitor=monitor,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "        # Early stopping 적용하기\n",
        "        early_stop_callback = EarlyStopping(\n",
        "            monitor=monitor,\n",
        "            patience=patience,\n",
        "            verbose=True,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "        # log\n",
        "        csv_logger = CSVLogger(save_dir, name=\"csv_logs\")\n",
        "\n",
        "        # train\n",
        "        self.trainer = Trainer(\n",
        "            accelerator='cuda',\n",
        "            max_epochs=epochs,\n",
        "            default_root_dir=save_dir,\n",
        "            callbacks=[checkpoint_callback, early_stop_callback],\n",
        "            logger=[csv_logger],\n",
        "            log_every_n_steps=len(train_loader)\n",
        "        )\n",
        "\n",
        "        self.trainer.fit(self, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "\n",
        "        r2_scores = [r2_score(target[:, i].detach().cpu(), output[:, i].detach().cpu()) for i in range(target.shape[1])]\n",
        "        maes = [mean_absolute_error(target[:, i].detach().cpu(), output[:, i].detach().cpu()) for i in range(target.shape[1])]\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "\n",
        "        # Log test metrics\n",
        "        self.log('test_loss', loss)\n",
        "        for i in range(target.shape[1]):\n",
        "            self.log(f'test_r2_{i}', r2_scores[i], prog_bar=True)\n",
        "            self.log(f'test_mae_{i}', maes[i], prog_bar=True)\n",
        "\n",
        "    def test(self, data_loader, device='cuda'):\n",
        "        self.trainer = Trainer(\n",
        "            accelerator=device,\n",
        "        )\n",
        "        results = self.trainer.test(self, dataloaders=data_loader)\n",
        "        return results\n",
        "\n",
        "\n",
        "    def infer(self, loader, scaler=None):\n",
        "        self.eval()\n",
        "        preds=[]\n",
        "        targets=[]\n",
        "        for data, target in loader:\n",
        "            with torch.no_grad():\n",
        "                pred = self(data)\n",
        "                preds.append(pred)\n",
        "                targets.append(target.numpy())\n",
        "        preds = np.concatenate(preds, axis=0)\n",
        "        targets = np.concatenate(targets, axis=0)\n",
        "\n",
        "        if scaler is not None:\n",
        "            preds = scaler.inverse_transform(preds)\n",
        "            targets = scaler.inverse_transform(targets)\n",
        "        return preds, targets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7_TYv-sJw3f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | **학습 및 평가**"
      ],
      "metadata": {
        "id": "Km-kJMCj9ZAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습**"
      ],
      "metadata": {
        "id": "XZocb-qu1iJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = train_pp.get_loader()\n",
        "test_loader = test_pp.get_loader()\n",
        "\n",
        "model =\n",
        "model.fit(train_loader, save_dir='test_effnet', valid_loader=test_loader, epochs=30)"
      ],
      "metadata": {
        "id": "2KNbAJa4eIW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**테스트**"
      ],
      "metadata": {
        "id": "cthb1ARK150F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CarhoodPredictor.load_from_checkpoint()\n",
        "model.test(test_loader)"
      ],
      "metadata": {
        "id": "3vsdRL1libw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**결과 시각화**"
      ],
      "metadata": {
        "id": "jYtqaHjj18Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds, targets = model.infer(test_loader, scaler=train_pp.scaler)\n",
        "draw_results(preds, targets, titles=var_columns)"
      ],
      "metadata": {
        "id": "2uzwiVJclWAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVkjTvsBTubS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}