{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "XxQZXje__Db7",
        "FQzXEbGCoerK",
        "SpSS_orNomwE",
        "g3ybYdw7--HX"
      ],
      "authorship_tag": "ABX9TyNdi2XZGmSusYo+6nPuCVon",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EilieYoun/Narnia-Edu/blob/main/Lecture/240813_snu/02_2D_Field_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 서울대 예측 AI 실습 : 2D Field Predict\n",
        "\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "\n",
        "## 학습내용\n",
        "```\n",
        "- 2D Field 데이터셋에 대해 이해하고 적절한 DataLoader를 구성 한다.\n",
        "- 2D Field 예측 문제에 적합한 모델을 구성하고, 학습을 진행한다.\n",
        "```"
      ],
      "metadata": {
        "id": "1PpOHlxlnDvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(0) 환경세팅**\n",
        "---"
      ],
      "metadata": {
        "id": "XxQZXje__Db7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 라이브러리 설치**"
      ],
      "metadata": {
        "id": "FQzXEbGCoerK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "02Ewuw33ad6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "lxaWDEQHdd5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 데이터 압축 풀기**"
      ],
      "metadata": {
        "id": "SpSS_orNomwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip carfield.zip -d ./carfield"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xJr20EeuwDjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Utils**"
      ],
      "metadata": {
        "id": "g3ybYdw7--HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def draw(imgs=[], cmap='RdBu_r', rows=None, save_path=None, mn=None, mx=None, colorbar=True):\n",
        "    num_imgs = len(imgs)\n",
        "    imgs = [img.astype(np.float32) for img in imgs]\n",
        "\n",
        "    if rows is None:\n",
        "        rows = 1  # Default to a single row if rows not specified\n",
        "\n",
        "    cols = (num_imgs + rows - 1) // rows  # Calculate the number of columns needed\n",
        "\n",
        "    plt.figure(figsize=(5*cols+2, 5*rows))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        if mn is None:\n",
        "          mn = min(img.min(), -img.max())\n",
        "        if mx is None:\n",
        "          mx = max(img.max(), -img.min())\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(img, cmap=cmap, vmin=mn, vmax=mx)\n",
        "        if colorbar:\n",
        "          plt.colorbar(shrink=0.4)\n",
        "        plt.axis('off')  # Hide axis for better visualization\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "\n",
        "    if save_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        plt.savefig(save_path, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "WLUUO_O5-9hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(1) Dataset**"
      ],
      "metadata": {
        "id": "vvsJn35E_F_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| EDA**\n",
        "\n",
        "**데이터 소개**\n",
        "\n",
        "[`CADillac`](https://kilthub.cmu.edu/articles/dataset/CADillac/8262593) 데이터셋에는 1,000개 이상의 고품질 3D 차량 모델이 포함되어 있습니다. 각 차량 모델은 Blender의 .blend 형식으로 제공되며, 차량의 크기, 색상, 유형 등의 메타 정보가 JSON 파일에 저장되어 있습니다.\n",
        "\n",
        "이번 시간에는 이 데이터를 가공한 2D 데이터를 사용합니다. 먼저, 각 차량의 3D 모델에 대해 풍동 실험의 CFD(전산유체역학) 시뮬레이션을 수행하여 시뮬레이션 공간 상의 3D 압력 필드를 계산했습니다. 이후, 차량의 3D 모델의 중앙 부분을 잘라 차량의 단면을 추출하고, 마찬가지로 3D 압력 필드의 중앙 부분 단면을 추출하여 각 차량의 단면과 해당 차량의 2D 압력 필드를 쌍으로 하는 데이터 셋을 만들었습니다. 이렇게 해서 총 367개의 데이터 쌍을 준비했습니다."
      ],
      "metadata": {
        "id": "J4BD_y6coTZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 경로 확보**"
      ],
      "metadata": {
        "id": "zvZf4fHCCnNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "image_paths= sorted(glob.glob('carfield/image/*npy'))\n",
        "field_paths = sorted(glob.glob('carfield/field/*npy'))\n",
        "print(len(image_paths), len(field_paths))"
      ],
      "metadata": {
        "id": "kGOnsBXofPSb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 시각화**"
      ],
      "metadata": {
        "id": "g9rNEtOLCpT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_sample = []\n",
        "field_sample = []\n",
        "for idx in range(3):\n",
        "    image_path = image_paths[idx]\n",
        "    field_path = field_paths[idx]\n",
        "    image = np.load(image_path)\n",
        "    field = np.load(field_path)\n",
        "    print(idx, image.shape, field.shape)\n",
        "\n",
        "    image_sample.append(image[0])\n",
        "    field_sample.append(field[0])\n",
        "\n",
        "draw(image_sample, mn=0, mx=255, cmap='gray')\n",
        "draw(field_sample)"
      ],
      "metadata": {
        "id": "zvihQ2DJ4WVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| DataLoader**\n",
        "\n",
        "간략하게 데이터 구성을 확인했으니 이를 적절한 `DataLoader` 클래스를 구축하겠습니다. `DataLoader`는 아래와 같은 기능이 포함되어야 합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 데이터셋 초기화.\n",
        "    - image_paths : 입력 (이미지) 데이터 경로\n",
        "    - field_paths : 출력 (필드) 데이터 경로\n",
        "    - batch_size : 배치 크기.\n",
        "    - shuffle : 데이터 셔플 여부.\n",
        "    - dtype : 데이터 유형 (torch.float32)\n",
        "    - aug : False : 데이터 증강\n",
        "\n",
        "- __len__ : 데이터셋의 전체 길이를 반환.\n",
        "\n",
        "- __getitem__ : 인덱스에 해당하는 데이터 항목을 반환.\n",
        "    - 데이터셋 불러오기\n",
        "    - 입력 데이터를 적절하게 스케일링\n",
        "    - 출력 데이터를 적절하게 스케일링\n",
        "    - 전처리된 인풋 텐서 (x)와 타깃 텐서 (y) 반환\n",
        "    - 데이터 증강\n",
        "    \n",
        "- get_loader : 데이터 로더를 반환.\n",
        "\n",
        "- get_batch : 지정된 인덱스의 배치를 반환.\n",
        "```\n"
      ],
      "metadata": {
        "id": "XVI4QnmYA7t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class CarFieldPorocess(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 image_paths,\n",
        "                 field_paths,\n",
        "                 batch_size=8,\n",
        "                 shuffle=True,\n",
        "                 dtype=torch.float32,\n",
        "                 aug=False\n",
        "                ):\n",
        "        # init\n",
        "        self.image_paths = image_paths\n",
        "        self.field_paths = field_paths\n",
        "\n",
        "        self.n_image = len(self.image_paths)\n",
        "        self.n_field = len(self.field_paths)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.dtype = dtype\n",
        "        self.aug =aug\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        x = np.load(path)\n",
        "\n",
        "        path = self.field_paths[idx]\n",
        "        y = np.load(path)\n",
        "\n",
        "        x = x / 255.\n",
        "        y = y / 600.\n",
        "\n",
        "        x = torch.tensor(x, dtype=self.dtype)\n",
        "        y = torch.tensor(y, dtype=self.dtype)\n",
        "\n",
        "        if self.aug:\n",
        "            if random.choice([True, False]):\n",
        "                flip = transforms.RandomHorizontalFlip(p=1)\n",
        "                x = flip(x)\n",
        "                y = flip(y)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def get_loader(self):\n",
        "        loader = DataLoader(self, batch_size=self.batch_size, shuffle=self.shuffle, pin_memory=True)\n",
        "        return loader\n",
        "\n",
        "    def get_batch(self, idx=0):\n",
        "        ds = self.get_loader()\n",
        "        for i, batch in enumerate(ds):\n",
        "            if i == idx : break\n",
        "        return batch"
      ],
      "metadata": {
        "id": "VIKvfPO5E1jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 분할**"
      ],
      "metadata": {
        "id": "8hXfUOTQyuSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습/테스트 데이터 분리\n",
        "train_image_paths, test_image_paths, train_field_paths, test_field_paths = train_test_split(\n",
        "    image_paths, field_paths, test_size=0.1, random_state=43\n",
        ")\n",
        "\n",
        "print('- Total dataset: ', len(image_paths), len(field_paths))\n",
        "print('- Train dataset: ', len(train_image_paths), len(train_field_paths))\n",
        "print('- Test dataset: ', len(test_image_paths), len(test_field_paths))"
      ],
      "metadata": {
        "id": "2LNW1vF-ydjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processor 구축**"
      ],
      "metadata": {
        "id": "Lahxh2CCy09u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pp = CarFieldPorocess(train_image_paths, train_field_paths, shuffle=True, batch_size=8, aug=True)\n",
        "test_pp = CarFieldPorocess(test_image_paths, test_field_paths, shuffle=False, batch_size=8, aug=False)\n",
        "\n",
        "train_xs, train_ys = train_pp.get_batch(0)\n",
        "print(train_xs.shape, train_ys.shape)\n",
        "draw(train_xs.numpy()[:,0], mn=0, mx=1, cmap='gray')\n",
        "draw(train_ys.numpy()[:,0])\n",
        "\n",
        "test_xs, test_ys = test_pp.get_batch(0)\n",
        "print(test_xs.shape, test_ys.shape)\n",
        "draw(test_xs.numpy()[:,0], mn=0, mx=1, cmap='gray')\n",
        "draw(test_ys.numpy()[:,0])"
      ],
      "metadata": {
        "id": "86CES0TbZIVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV1cR283HndF"
      },
      "source": [
        "\n",
        "## **(2) 모델**\n",
        "---\n",
        "\n",
        "이번 시간에 사용할 모델은 `UNet`입니다. `UNet`은 주로 이미지 분할 작업에 사용되는 신경망으로, U자형 아키텍처를 통해 다양한 해상도에서 특징을 추출하고 결합하여 높은 성능을 발휘합니다.\n",
        "\n",
        "`UNet`을 사용하여 이미지 세그멘테이션뿐만 아니라 압력 필드를 예측할 수도 있습니다. 예를 들어, 1채널의 `128x256` 크기 흑백 차량 이미지를 입력으로 받아, 동일한 크기의 1채널 압력 필드를 출력하는 모델을 구축할 수 있습니다. `UNet`의 구조는 이미지의 세부 정보를 잘 유지하면서도 압력 필드 예측과 같은 작업에서 높은 성능을 제공합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Structure 구축**\n",
        "\n",
        "* 이미지 출처 : (https://arxiv.org/pdf/1505.04597)\n",
        "\n",
        "<img src=\"https://github.com/Narnialabs/Narnia-Edu/blob/main/Lecture/imgs/2408_Seoul_02_01.png?raw=true\" alt=\"UNet\" width=\"700\"/>\n",
        "\n",
        "\n",
        "\n",
        "`UNet` 기반 회귀 모델인 `UNetStructure`의 구조를 정의합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 사전 학습된 `UNet` 모델을 불러오고 문제에 맞게 적절히 변환합니다.\n",
        "    - in_channels : 첫번째 컨볼루션 레이어의 입력 channel 개수 입니다.\n",
        "    - out_channels : 마지막 완전연결 레이어의 출력 feature 개수 입니다.\n",
        "\n",
        "- forward : 입력 데이터를 모델에 전달하여 예측 값을 반환합니다.\n",
        "```"
      ],
      "metadata": {
        "id": "Sv3wyN7O0hZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from segmentation_models_pytorch import Unet\n",
        "\n",
        "# U-Net 모델 정의\n",
        "class UNetStructure(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super(UNetStructure, self).__init__()\n",
        "        self.unet = Unet(encoder_name='resnet34', encoder_weights='imagenet', in_channels=in_channels, classes=out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.unet(x)"
      ],
      "metadata": {
        "id": "zcMPRi_DdJDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNet 모델 생성**"
      ],
      "metadata": {
        "id": "KJaY8tl8z_y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet = UNetStructure(in_channels=1, out_channels=1)"
      ],
      "metadata": {
        "id": "B_Dga5mYdvyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 입력과 출력 확인**"
      ],
      "metadata": {
        "id": "vE79wsrk0CJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 1, 128, 256)\n",
        "preds = unet(x)\n",
        "preds.shape"
      ],
      "metadata": {
        "id": "MIyPaQ6PnPUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 모델 구축**\n",
        "\n",
        "`PyTorch Lightning`을 사용하여 훈련, 검증, 최적화 루틴을 포함하는 `CarhoodPredictor`를 정의합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 예측 모델(predictor)을 초기화합니다.\n",
        "- forward : 입력 데이터를 예측 모델에 전달하여 출력을 반환합니다.\n",
        "- configure_optimizers : Adam 옵티마이저와 코사인 조정 학습률 스케줄러를 설정합니다.\n",
        "- training_step : 훈련 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 손실을 계산하여 로깅합니다.\n",
        "- validation_step : 검증 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 손실을 계산하여 로깅합니다.\n",
        "- fit : 훈련 및 검증 데이터를 사용하여 모델을 훈련합니다. 조기 종료와 체크포인트 저장 기능을 포함합니다.\n",
        "- test_step : 테스트 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 성능 지표를 로깅합니다.\n",
        "- test : 테스트 데이터를 사용하여 모델 성능을 평가합니다.\n",
        "- infer : 주어진 데이터 로더에서 예측을 수행하고, 필요 시 스케일러를 사용하여 예측값을 역변환합니다.\n",
        "```"
      ],
      "metadata": {
        "id": "kciU309YeJg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import  CSVLogger\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "class FieldPredictor(pl.LightningModule):\n",
        "    def __init__(self, structure, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.structure = structure\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.structure(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.init_lr)\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
        "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"epoch\"}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('learning_rate', lr, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss =  nn.MSELoss()(output, target)\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "\n",
        "        self.log('valid_loss', loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def fit(self,\n",
        "            train_loader,\n",
        "            save_dir,\n",
        "            valid_loader=None,\n",
        "            init_lr=1e-3,\n",
        "            epochs=10,\n",
        "            patience=5,\n",
        "            infer_ds = None):\n",
        "\n",
        "        self.init_lr = init_lr\n",
        "        self.save_dir = save_dir\n",
        "        self.epochs = epochs\n",
        "        self.infer_ds = infer_ds\n",
        "\n",
        "        # valid loss 기준으로 최적 모델 저장하기\n",
        "        if valid_loader is not None:\n",
        "            monitor = 'valid_loss'\n",
        "        else:\n",
        "            monitor = 'train_loss'\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            dirpath=save_dir,\n",
        "            filename='ckp_model',\n",
        "            save_top_k=1,\n",
        "            verbose=True,\n",
        "            monitor=monitor,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "        # log\n",
        "        csv_logger = CSVLogger(save_dir, name=\"csv_logs\")\n",
        "\n",
        "        # train\n",
        "        self.trainer = Trainer(\n",
        "            accelerator='cuda',\n",
        "            max_epochs=epochs,\n",
        "            default_root_dir=save_dir,\n",
        "            callbacks=[checkpoint_callback],\n",
        "            logger=[csv_logger],\n",
        "            log_every_n_steps=len(train_loader)\n",
        "        )\n",
        "\n",
        "        self.trainer.fit(self, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "        self.log('test_loss', loss)\n",
        "\n",
        "\n",
        "    def test(self, data_loader, device='cuda'):\n",
        "        self.trainer = Trainer(\n",
        "            accelerator=device,\n",
        "        )\n",
        "        results = self.trainer.test(self, dataloaders=data_loader)\n",
        "        return results\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        imgs=[]\n",
        "        xs, ys = self.infer_ds\n",
        "        preds = self(xs.cuda())\n",
        "\n",
        "        xs = xs.numpy()[:,0]\n",
        "        ys = ys.numpy()[:,0]\n",
        "        preds = preds.detach().cpu().numpy()[:,0]\n",
        "\n",
        "        imgs.extend(xs)\n",
        "        imgs.extend(ys)\n",
        "        imgs.extend(preds)\n",
        "\n",
        "\n",
        "        if bool(imgs):\n",
        "            epoch = self.trainer.current_epoch\n",
        "            draw(np.array(imgs),\n",
        "                     save_path=f'./{self.save_dir}/sample_epoch_{epoch:05d}.png',\n",
        "                     rows=3,\n",
        "                    )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7_TYv-sJw3f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | **학습 및 평가**"
      ],
      "metadata": {
        "id": "Km-kJMCj9ZAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 인스턴스**"
      ],
      "metadata": {
        "id": "sw4Zp8U8FZTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FieldPredictor(structure=unet)"
      ],
      "metadata": {
        "id": "2KNbAJa4eIW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습**"
      ],
      "metadata": {
        "id": "XZocb-qu1iJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = train_pp.get_loader()\n",
        "test_loader = test_pp.get_loader()\n",
        "\n",
        "model.fit(train_loader, save_dir='unet_field', valid_loader=test_loader, epochs=30, infer_ds = [test_xs, test_ys])"
      ],
      "metadata": {
        "id": "4VoL8pjM966Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**테스트**"
      ],
      "metadata": {
        "id": "cthb1ARK150F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FieldPredictor.load_from_checkpoint('./unet_field/ckp_model.ckpt', structure=unet)\n",
        "model.test(test_loader)"
      ],
      "metadata": {
        "id": "3vsdRL1libw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_xs, test_ys = test_pp.get_batch(0)\n",
        "preds = model(test_xs)\n",
        "\n",
        "test_xs = test_xs.numpy()[:,0]\n",
        "test_ys = test_ys.numpy()[:,0]\n",
        "preds = preds.detach().cpu().numpy()[:,0]\n",
        "\n",
        "# scale 조정\n",
        "test_ys = (test_ys + 1. ) / 2.\n",
        "preds = (preds + 1. ) / 2.\n",
        "\n",
        "diffs = np.abs(test_ys - preds)\n",
        "\n",
        "print(train_xs.shape, test_ys.shape, preds.shape, diffs.shape)"
      ],
      "metadata": {
        "id": "_TmgFzCoGy7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw(test_xs[:4], mn=0., mx=1., cmap='gray') # input image\n",
        "draw(test_ys[:4], mn=0., mx=1. ) # real field map\n",
        "draw(preds[:4], mn=0., mx=1.) # model field map\n",
        "draw(diffs[:4], mn=0., mx=1.) # error map"
      ],
      "metadata": {
        "id": "rb0QMmzRIKXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWp12uhJvfzt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}