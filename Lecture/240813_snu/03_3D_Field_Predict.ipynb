{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FQzXEbGCoerK",
        "SpSS_orNomwE",
        "g3ybYdw7--HX"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMS5e5m5WUQHj/4BejU8HzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EilieYoun/Narnia-Edu/blob/main/Lecture/240813_snu/03_3D_Field_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 서울대 예측 AI 실습 : 3D Field Predict\n",
        "\n",
        "\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "\n",
        "## 학습내용\n",
        "```\n",
        "- 3D 데이터셋에 대해 이해하고 적절한 DataLoader를 구성 한다.\n",
        "- 3D Field 예측 문제에 적합한 모델을 구성하고, 학습을 진행한다.\n",
        "```"
      ],
      "metadata": {
        "id": "1PpOHlxlnDvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(0) 환경세팅**\n",
        "---"
      ],
      "metadata": {
        "id": "XxQZXje__Db7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 라이브러리 설치**"
      ],
      "metadata": {
        "id": "FQzXEbGCoerK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "02Ewuw33ad6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchio monai"
      ],
      "metadata": {
        "id": "MAsT-pvmJYKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 데이터 압축 풀기**"
      ],
      "metadata": {
        "id": "SpSS_orNomwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bracket_field.zip -d ./bracket_field"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xJr20EeuwDjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| Utils**"
      ],
      "metadata": {
        "id": "g3ybYdw7--HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "\n",
        "\n",
        "def plot_voxel(voxel_grid):\n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "\n",
        "    ax1 = fig.add_subplot(111, projection='3d')\n",
        "    ax1.voxels(voxel_grid, edgecolor='k')\n",
        "    ax1.set_title('Voxel visualization')\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def plot_voxel_grid(grid, mask, alpha=0.7):\n",
        "    grid_shape = grid.shape\n",
        "\n",
        "    colors = plt.cm.rainbow(grid)\n",
        "    colors[..., 3] = alpha  # alpha 채널 추가\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "    ax1 = fig.add_subplot(111, projection='3d')\n",
        "    ax1.voxels(mask, facecolors=colors, edgecolor='none')\n",
        "    ax1.set_xlabel('X')\n",
        "    ax1.set_ylabel('Y')\n",
        "    ax1.set_zlabel('Z')\n",
        "    cb1 = fig.colorbar(plt.cm.ScalarMappable(cmap='rainbow', norm=plt.Normalize(vmin=0, vmax=1.1)), ax=ax1, shrink=0.5)\n",
        "    cb1.set_label('Value')\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# 3차원데이터의 위에서 본 모습만 2d plot으로 그리기 -> 굉장히 빠르게 시각화 진행가능\n",
        "def plot_topview(xs, alpha=0.8, save_path=None, rows=1, mn=None, mx=None):\n",
        "    n = len(xs)\n",
        "    cols = (n + rows - 1) // rows  # Calculate the number of columns needed\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))\n",
        "    axs = np.array(axs).reshape(rows, cols)  # Ensure axs is a 2D array\n",
        "\n",
        "    for i, (ax, x) in enumerate(zip(axs.flatten(), xs)):\n",
        "        top_view = np.max(x, axis=2)[::-1]\n",
        "\n",
        "        cax1 = ax.imshow(top_view, cmap='rainbow', alpha=alpha, origin='lower', vmin=mn, vmax=mx)\n",
        "        cb1 = fig.colorbar(cax1, ax=ax, shrink=0.75)\n",
        "        cb1.set_label('Value')\n",
        "\n",
        "    for ax in axs.flatten()[n:]:\n",
        "        ax.axis('off')  # Turn off axes for any extra subplots\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "WLUUO_O5-9hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **(1) Dataset**"
      ],
      "metadata": {
        "id": "vvsJn35E_F_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| EDA**\n",
        "\n",
        "**데이터 소개**\n",
        "\n",
        "`Simulated Jet Engine Bracket Dataset (SimJEB)` 는 다양한 용도로 사용 가능한 공개 데이터셋입니다. 이 데이터셋은 기하학적 처리 및 대체 모델링 알고리즘 테스트, 구조 설계 전략 연구 등에 활용될 수 있습니다. 데이터셋은 2013년 \"GE 제트 엔진 브래킷 챌린지\"의 디자인을 기반으로 하며, 정리, 방향 설정, 스케일 조정, 메싱, 시뮬레이션 과정을 거친 디자인을 포함하고 있습니다​\n",
        "\n",
        "이번 시간에 다룰 데이터는 `SimJEB` STL 32x32x32 해상도의 데이터의 각 지점에서의 변위를 측정한 것입니다. 변위는 구조 해석, 지진 공학, 재료 과학 등 다양한 분야에서 중요한 역할을 합니다. 예를 들어, 구조물의 변위를 측정함으로써 구조물의 안정성을 평가하고, 지진 시 구조물의 거동을 분석할 수 있습니다.  변위가 작으면 구조물의 손상 가능성이 줄어들고 구조적 안정성을 확보할 수 있습니다."
      ],
      "metadata": {
        "id": "J4BD_y6coTZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "paths = sorted(glob.glob('./bracket_field/*.npy'))\n",
        "print(len(paths))"
      ],
      "metadata": {
        "id": "kGOnsBXofPSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 시각화**"
      ],
      "metadata": {
        "id": "g9rNEtOLCpT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 32\n",
        "data = np.load(paths[idx])\n",
        "print('data shape: ', data.shape)\n",
        "\n",
        "plot_voxel(data) # 0 또는 1로만 되어있는거 처럼 보이지만 실제로는 그렇지 않다.\n",
        "\n",
        "# plot_voxel_grid: 모든 값을 값에 따라 다른 색깔로 표현\n",
        "plot_voxel_grid(data, data!=0) # data가 0이 아닌 영역만 그리기"
      ],
      "metadata": {
        "id": "zvihQ2DJ4WVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_=plt.hist(data.flatten()) # 0인 부분은 빈공간, 그외 부분은 0 ~ 1.09~ 정도의 변위값을 지니고 있다."
      ],
      "metadata": {
        "id": "h-AVVxv1lcBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| DataLoader**\n",
        "\n",
        "간략하게 데이터 구성을 확인했으니 이를 적절한 `DataLoader` 클래스를 구축하겠습니다. `DataLoader`는 아래와 같은 기능이 포함되어야 합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 데이터셋 초기화.\n",
        "    - field_paths :\n",
        "    - batch_size: 8\n",
        "    - shuffle: True\n",
        "    - dtype: torch.float32\n",
        "    - dtype: 데이터 유형 (torch.float32 기본값).\n",
        "\n",
        "- __len__ : 데이터셋의 전체 길이를 반환.\n",
        "\n",
        "- __getitem__ : 인덱스에 해당하는 데이터 항목을 반환.\n",
        "    - DataFrame을 로드하여 필요한 데이터 불러오기\n",
        "    - 성능 변수를 적절하게 정규화\n",
        "    - 전처리된 인풋 텐서 (x)와 타깃 텐서 (y) 반환\n",
        "    \n",
        "- get_loader : 데이터 로더를 반환.\n",
        "\n",
        "- get_batch : 지정된 인덱스의 배치를 반환.\n",
        "```\n"
      ],
      "metadata": {
        "id": "XVI4QnmYA7t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class BracketFieldProcess(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "               field_paths,\n",
        "               batch_size=8,\n",
        "               shuffle=True,\n",
        "               dtype=torch.float32\n",
        "               ):\n",
        "\n",
        "    self.field_paths = field_paths\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.dtype = dtype\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.field_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    field_path = self.field_paths[idx]\n",
        "    field = np.load(field_path) # 32,32,32\n",
        "    voxel = np.where(field==0, 0, 1) # 32,32,32\n",
        "\n",
        "    mask = (field!=0)  # bkg아닌 변위 값이 존재하는 곳\n",
        "    field[mask] = np.log(field[mask]) * -1. / 10. # 변위 값을 log 변형\n",
        "\n",
        "    voxel = torch.from_numpy(voxel).type(self.dtype).unsqueeze(0) # 1, 32, 32, 32\n",
        "    field = torch.from_numpy(field).type(self.dtype).unsqueeze(0) # 1, 32, 32, 32\n",
        "\n",
        "    return voxel, field\n",
        "\n",
        "\n",
        "\n",
        "  def get_loader(self):\n",
        "    loader = DataLoader(self, batch_size=self.batch_size, shuffle=self.shuffle, pin_memory=True)\n",
        "    return loader\n",
        "\n",
        "  def get_batch(self, idx=0):\n",
        "    ds = self.get_loader()\n",
        "    for i, batch in enumerate(ds):\n",
        "        if i == idx : break\n",
        "    return batch"
      ],
      "metadata": {
        "id": "VIKvfPO5E1jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 분할**"
      ],
      "metadata": {
        "id": "8hXfUOTQyuSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_paths, test_paths = train_test_split(paths, test_size=0.1, random_state=42)\n",
        "print(len(paths), len(train_paths), len(test_paths))"
      ],
      "metadata": {
        "id": "2LNW1vF-ydjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processor 구축**"
      ],
      "metadata": {
        "id": "Lahxh2CCy09u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bsz = 8\n",
        "train_pp = BracketFieldProcess(train_paths, batch_size=bsz, shuffle=True)\n",
        "test_pp = BracketFieldProcess(train_paths, batch_size=bsz, shuffle=False)"
      ],
      "metadata": {
        "id": "GKYpkIW8By1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch 데이터 확인**"
      ],
      "metadata": {
        "id": "hB38qvPU0qnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_xs, train_ys = train_pp.get_batch(0)\n",
        "print('- Train batch shape: ', train_xs.shape, train_ys.shape)\n",
        "plot_topview(train_xs[:,0].numpy()) # n, 32, 32, 32 numpy array\n",
        "plot_topview(train_ys[:,0].numpy())\n",
        "\n",
        "test_xs, test_ys = test_pp.get_batch(0)\n",
        "print('- Test batch shape: ', test_xs.shape, test_ys.shape)\n",
        "plot_topview(test_xs[:,0].numpy())\n",
        "plot_topview(test_ys[:,0].numpy())"
      ],
      "metadata": {
        "id": "3FTIm26UfNUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y  = train_ys.numpy().flatten()\n",
        "mask = (y!=0)  # bkg아닌 변위 값이 존재하는 곳\n",
        "\n",
        "y[mask] = np.log(y[mask]) * -1. / 10.\n",
        "_=plt.hist(y[mask], bins=50)\n",
        "_=plt.hist(y, bins=50)"
      ],
      "metadata": {
        "id": "YiZ0XInpraVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV1cR283HndF"
      },
      "source": [
        "\n",
        "## **(2) 모델**\n",
        "---\n",
        "\n",
        "* 이미지 출처 : (https://github.com/AghdamAmir/3D-UNet)\n",
        "\n",
        "<img src=\"https://github.com/AghdamAmir/3D-UNet/raw/main/3D-UNET.png\" alt=\"UNet\" width=\"700\"/>\n",
        "\n",
        "이번 시간에는 `monai.networks.nets` 의 `UNet` 이용해 `3D Unet`을 구축하겠습니다. 이 모델은 1, 32, 32, 32 인풋을 받아 다시 1, 32, 32, 32 크기의 아웃풋을 내놓는 모델이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from monai.networks.nets import UNet\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.unet = UNet(\n",
        "            spatial_dims = 3,\n",
        "            in_channels = in_channels,\n",
        "            out_channels = out_channels,\n",
        "            channels = (16, 32, 64, 128, 256),\n",
        "            strides = (2,2,2,2),\n",
        "            num_res_units = 2,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.unet(x)"
      ],
      "metadata": {
        "id": "6TwWsJc0JPu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 생성\n",
        "structure = UNet3D()\n",
        "\n",
        "# 모델구조 테스트\n",
        "# 입력 데이터\n",
        "inputs = torch.randn(1, 1, 32, 32, 32) # (n, 1, 32, 32, 32)\n",
        "outputs = structure(inputs)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "id": "GDHjM4FOJdjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **| 모델 구축**\n",
        "\n",
        "`PyTorch Lightning`을 사용하여 훈련, 검증, 최적화 루틴을 포함하는 `BracketFieldPredictor`를 정의합니다.\n",
        "\n",
        "```\n",
        "- __init__ : 예측 모델(predictor)을 초기화합니다.\n",
        "- forward : 입력 데이터를 예측 모델에 전달하여 출력을 반환합니다.\n",
        "- configure_optimizers : Adam 옵티마이저와 코사인 조정 학습률 스케줄러를 설정합니다.\n",
        "- training_step : 훈련 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 손실을 계산하여 로깅합니다.\n",
        "- validation_step : 검증 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, MSE 손실을 계산하여 로깅합니다.\n",
        "- fit : 훈련 및 검증 데이터를 사용하여 모델을 훈련합니다. 조기 종료와 체크포인트 저장 기능을 포함합니다.\n",
        "- test_step : 테스트 배치에서 입력 데이터와 타깃을 받아 모델 출력을 계산하고, R² 점수와 MAE를 포함한 성능 지표를 로깅합니다.\n",
        "- test : 테스트 데이터를 사용하여 모델 성능을 평가합니다.\n",
        "- infer : 주어진 데이터 로더에서 예측을 수행하고, 필요 시 스케일러를 사용하여 예측값을 역변환합니다.\n",
        "```"
      ],
      "metadata": {
        "id": "kciU309YeJg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import  CSVLogger\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "\n",
        "class BracketFieldPredictor(pl.LightningModule):\n",
        "    def __init__(self, structure, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.structure = structure\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.structure(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.init_lr)\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
        "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"epoch\"}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('learning_rate', lr, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss =  nn.MSELoss()(output, target)\n",
        "        lr = self.optimizers().param_groups[0]['lr']\n",
        "\n",
        "        self.log('valid_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def fit(self, train_loader, save_dir,  valid_loader=None, init_lr=1e-3, epochs=10, patience=5, infer_ds=None):\n",
        "        self.init_lr = init_lr\n",
        "        self.epochs = epochs\n",
        "        self.infer_ds = infer_ds\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        # valid loss 기준으로 최적 모델 저장하기\n",
        "        if valid_loader is not None:\n",
        "            monitor = 'valid_loss'\n",
        "        else:\n",
        "            monitor = 'train_loss'\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            dirpath=save_dir,\n",
        "            filename='ckp_model',\n",
        "            save_top_k=1,\n",
        "            verbose=True,\n",
        "            monitor=monitor,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "        # log\n",
        "        csv_logger = CSVLogger(save_dir, name=\"csv_logs\")\n",
        "\n",
        "        # train\n",
        "        self.trainer = Trainer(\n",
        "            accelerator='cuda',\n",
        "            max_epochs=epochs,\n",
        "            default_root_dir=save_dir,\n",
        "            callbacks=[checkpoint_callback],\n",
        "            logger=[csv_logger],\n",
        "            log_every_n_steps=len(train_loader)\n",
        "        )\n",
        "\n",
        "        self.trainer.fit(self, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        data, target = batch\n",
        "        output = self(data)\n",
        "        loss = nn.MSELoss()(output, target)\n",
        "        self.log('test_loss', loss)\n",
        "\n",
        "    def test(self, data_loader, device='cuda'):\n",
        "        self.trainer = Trainer(\n",
        "            accelerator=device,\n",
        "        )\n",
        "        results = self.trainer.test(self, dataloaders=data_loader)\n",
        "        return results\n",
        "\n",
        "    def on_train_epoch_end(self): # lightning 모듈에서 이미 정의되어있는 함수. (1epoch 끝날때마다 자동 실행)\n",
        "        # 모델이 잘 학습되고 있는지 시각화를 해보자\n",
        "\n",
        "        # inference 에 필요한 데이터\n",
        "        if self.infer_ds is not None:\n",
        "          imgs  = []\n",
        "          xs, ys = self.infer_ds\n",
        "          preds = self(xs.cuda())\n",
        "\n",
        "          # numpy 로 변경, 차원 변경(n, 1, 32, 32, 32) -> (n, 32, 32, 32)\n",
        "          xs = xs.numpy()[:,0]\n",
        "          ys = ys.numpy()[:,0]\n",
        "          preds = preds.detach().cpu().numpy()[:,0]\n",
        "\n",
        "          imgs.extend(xs)\n",
        "          imgs.extend(ys)\n",
        "          imgs.extend(preds)\n",
        "          # imgs = [x1, x2, x3, ... y1, y2, y3 ... pred1, pred2, ...]\n",
        "\n",
        "          epoch = self.trainer.current_epoch\n",
        "          plot_topview(\n",
        "              np.array(imgs),\n",
        "              save_path = f'{self.save_dir}/sample_e{epoch:05d}.png',\n",
        "              rows=3, # 이미지 3줄로 출력\n",
        "          )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7_TYv-sJw3f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | **학습 및 평가**"
      ],
      "metadata": {
        "id": "Km-kJMCj9ZAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 인스턴스**"
      ],
      "metadata": {
        "id": "sw4Zp8U8FZTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BracketFieldPredictor(structure=structure)"
      ],
      "metadata": {
        "id": "2KNbAJa4eIW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**학습**"
      ],
      "metadata": {
        "id": "XZocb-qu1iJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = train_pp.get_loader()\n",
        "test_loader = test_pp.get_loader()\n",
        "test_xs, test_ys = test_pp.get_batch(0)\n",
        "model.fit(train_loader, save_dir='unet3d_1', valid_loader = test_loader, epochs=100, infer_ds = [test_xs, test_ys], init_lr=1e-3)"
      ],
      "metadata": {
        "id": "4VoL8pjM966Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**테스트**"
      ],
      "metadata": {
        "id": "cthb1ARK150F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BracketFieldPredictor.load_from_checkpoint('./unet3d_1/ckp_model.ckpt', structure=structure)\n",
        "model.test(test_loader)"
      ],
      "metadata": {
        "id": "3vsdRL1libw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**결과 시각화**"
      ],
      "metadata": {
        "id": "hvOci5YK1O7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(test_xs)\n",
        "preds = preds.detach().cpu().numpy()[:,0]\n",
        "reals = test_ys.numpy()[:,0]\n",
        "diffs = np.abs(reals - preds)\n",
        "\n",
        "plot_topview(reals)\n",
        "plot_topview(preds)\n",
        "plot_topview(diffs, mn=0, mx=1)"
      ],
      "metadata": {
        "id": "uiL0PFVuJQi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "plot_voxel_grid(reals[idx], reals[idx]!=0)\n",
        "plot_voxel_grid(preds[idx], reals[idx]!=0) # 모델이 예측한 preds 의 배경은 preds 값 기준이 아닌 인풋 데이터 기준으로 배경을 설정\n",
        "plot_voxel_grid(diffs[idx], reals[idx]!=0, alpha=0.4)"
      ],
      "metadata": {
        "id": "svT2moDH-8h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URQTUdAS-x1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}